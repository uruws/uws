* Last 7 days [changelog][weekly-changelog]

[weekly-changelog]: https://github.com/TalkingPts/Infrastructure/compare/master%40%7B7days%7D...master

---

* Infra Development Backlog - `WAITING`
    * App Cache-Control header for CDN assets - [DEV-9810][DEV-9810]
    * App api clients domain - [DEV-9833][DEV-9833]

[DEV-9810]: https://talkingpointsorg.atlassian.net/browse/DEV-9810
[DEV-9833]: https://talkingpointsorg.atlassian.net/browse/DEV-9833

---

* block web access by geoip - `WIP`
    * It's already in place for app.t.o
    * We need to set it up for api.t.o
    * appcdn.uws.t.o only from US/Cloudfront? UY too maybe?
    * staging.t.o too?

---

* tapo3: deployment setup using AWS ALB and WAF services - `WIP` [PR265][PR265]

[PR265]: https://github.com/TalkingPts/Infrastructure/pull/265

---

* tapo: new cluster appc5nxl-2309 - `DONE!` [PR266][PR266]
    * ec2 type c5n.xlarge cluster

[PR266]: https://github.com/TalkingPts/Infrastructure/pull/266

---

* rstudio: xiaoyuan user - `DONE!` [PR267][PR267]

[PR267]: https://github.com/TalkingPts/Infrastructure/pull/267

---

* rstudio: python3 venv - `DONE!` [PR268][PR268]

[PR268]: https://github.com/TalkingPts/Infrastructure/pull/268

---

* tapo: c5n.xlarge setup - `DONE!` [PR269][PR269]

[PR269]: https://github.com/TalkingPts/Infrastructure/pull/269

---

* security: Debian linux kernel upgrade [DSA-5492-1][DSA-5492-1] - `DONE!`
    * jsbatch upgrade
    * rstudio-ousd upgrade
    * k8s nodes upgrade
        * Even if those are not Debian boxes, still...

[DSA-5492-1]: https://www.debian.org/security/2023/dsa-5492

---

* 2309 [upgrades][upgrades] round

[upgrades]: ./infra/upgrades.md

---

* tapo: fix deploy restart
    * some configmaps and/or secrets are not properly reloaded when we do restart, which re-generates those files in case of new settings
    * probably it's better to just dispatch a new deploy using current version

---

* munin: fix k8s pods state OOMKilled count bug
    * it's not counting the OOMKilled correctly
    * I think that it's due to the fact that those are in a "not running" state

---

* munin: check internal CAs expiration date
    * ops
    * opstest
    * smtps

---

* munin: deprecate apijob (worker jobs)
    * it will be done from infra-ui project

---

* meteor secrets: pull from heroku
    * pull heroku env vars for aws deploy/restart
    * remove: secret/eks/files/meteor

---

* docker: mailx via amazon-ses
    * setup msmtp to send emails via amazon-ses
    * msmtprc should be templated/generated by environment
        * like jsbatch
        * container X
        * k8s services
        * etc

---

* k8s deploy: check critical service rollin
    * currently we have alerts for container restarts and such
    * but if a deployment gets rolled in (or deleted someway) we don't have any alert
        * ie: app-rollin worker

---

* Buildpack:
    * add start/end date time info to build logs to track elapsed time
    * currently two log files are created, should be only one
        * one for make _app_
        * other for the make deploy
        * if app-build sets the LOGFILE env var makefiles could use that one

---

* k8s: prom+grafana cluster local dashboard for on-the-fly metrics

---

* haproxy: metrics
    * integrate with k8s dashboard
    * integrate with munin

---

* k8smon: munin network usage graphs
    * by namespace
    * by node
    * total
    * by pod/container?

---

* uwscli: meteor deploy to heroku to keep versions in sync

---

* uwscli new build/console server
    * run autobuilds there
    * with more CPU and MEM
    * do we move uwscli tools to there?
    * or do we make app-build dispatch the build on the build server?

---

* uwscli: nq deploy so once they start can not be stopped by ctrl+c or similar
    * we mainly need it for when custom deploys are launched
    * so maybe we have to nq deploys and also the custom deploy too

---

* `SEC` `CRITICAL` infra internal domain
	* get a new and separate domain to isolate from main domain
	* we should replace uws.t.o with this new domain
	* we should also setup mailx for this domain to also separate from main domain accounts
		* we should use this domain for critical/internal/3rd party accounts
		* AWS accounts in example should use this separate domain
		* any 3rd party integration (Jira, Bandwidth, etc, etc, etc) should use accounts on this domain
		* all these mainly due to the Ramp integration the Finance people asked about which requires read access to ALL domain accounts

---

* meteor: accelerate build time using local caches/proxy/repo for npm dependencies

---

* munin: check that App response headers include the "security headers" we need for SOC2
    * https://staging.t.o/login
        * Content-Security-Policy
        * Cross-Origin-Resource-Policy
        * Access-Control-Allow-Origin
        * Referrer-Policy

---

* munin: alert about workers callback http errors [worker-errors][worker-errors]
    * warning at 3 errors per minute
    * critical at 5 errors per minute
    * send alert to status page

[worker-errors]: https://worker-2209.uws.talkingpts.org/munin/uws/worker-2209/web_request_worker_uws_talkingpts_org/errors_per_minute.html

---

* `SEC` App security changes
    * Remove private/settings.json from the repo

---

* `SEC` `FIX` Firebase content is discoverable:
    * https://firebasestorage.googleapis.com/v0/b/talkingpnts.appspot.com/o/
    * working in an unrelated issue with Gabriel we found out that ^
    * we should use a CDN for that too, and avoid this issue and also improve performance and costs

---

* munin cluster's storage archive/sync to jsbatch or similar
    * for archiving/history and backup purposes
    * also to have some data available in case of the cluster being down
        * even if it will be old data, could be useful still
    * graph for nodes region/zones
    * nodes types
        * pass INSTANCE_TYPES env var to munin-node and keep them in the graph
    * graphs for PVs/PVCs?
        * available storage
        * region/zones

---

* app-autoscale
    * implement auto scaler based on custom metrics
        * web: scale based on web traffic/requests per minute
            * more or less, nowadays, 10 containers to serve 1000 rpm
            * [DB query](./worker-check-scheduled-jobs.txt)
        * workers:
            * cleverSynch could/should be another metric as it needs to finish before 10hs UTC
            * messages.jobs ready?
            * one metric could be based on checking scheduled district jobs to scale up before it starts, instead of reacting to an alert

---

* forensics setup

---

* CA rotate ops/210823

---

* munin
    * graph/check nodegroup status (alert when it's DEGRADED or not ACTIVE)
    * uwseks get nodegroup -n main -o json
    * check that munin-node container/service is running via k8smon "proxy"

---

* implement [node inspector][node-inspector] setup using the SSH approach
    * the idea is to have a way to dispatch "debugging containers" which could be inspected using chrome dev tools or similar, using the SSH tunneling setup as it seems to be the more secure for our infra
    * the SSH service should be only enabled when we dispatch the debug containers, using a random public port ideally and setting a random password for the uws user inside the container (show that password in the container init steps or similar) so we can share that info (port and password) "securely" as it's generated every time the container starts

[node-inspector]: https://nodejs.org/en/docs/guides/debugging-getting-started/

---

* `FIX` implement a "double check" mechanism for changing DNS uws.t.o domain records
    * the idea is to avoid issues like the one I did changing a production record
    * maybe use an script for Route53 editions which alerts about prod domains or similar
    * try to avoid manual changes (maybe some peer review?)

---

* munin: scan cluster ingress domains and add them to the checks (munin-node-clusters)

---

* aws support meeting
    * Route53 app.t.o use geolocation inside US or latency setup
        * versus current weighted 50/50 setup
        * we must keep the "heroku contingency plan" setup or adapt it to new ways

---

* uwscli:
    * cleanup old images in ECR
    * app-build
        * we should be able to properly stop/abort a building process
    * show events log or auto-refresh status info
    * control deploy replicas
    * cli/buildpack.sh: should manage the log and email report if any fail
    * cli/app-build.sh: should do the same

---

* uwsq: clean failed jobs

---

* `SEC` mongodb credentials rotation schedule

---

* `SEC` aws auth credentials rotation schedule
    * uwsadm and friends "access keys"

---

* munin pods_container (check phase)
    "status": {
        "message": "The node was low on resource: memory. Container controller was using 2391212Ki, which exceeds its request of 90Mi. ",
        "phase": "Failed",
        "reason": "Evicted",
        "startTime": "2022-02-09T03:24:23Z"
    }

---

* munin alerts to slack
    * setup/devel bot
    * remove setup munin limit mail alerts
        * dev_ops_vo548nvb
            * munin-alerts TO
            * gmail fetch
            * create forward rules to slack and others

---

* ansible roles
    * monit
        * setup monit to check fail2ban keeps running
        * and others...
    * fail2ban
    * munin

---

* non-prod sites robots.txt to disallow all crawlers?

---

* infra docs for internal presentation
